---
title: 'Case Study: USOEA'
author: "Bahirah Adewunmi"
date: "January 17, 2018"
output:
  html_document:
    df_print: paged
  pdf_document: default
editor_options:
  chunk_output_type: console
---

#Installing and Import Needed Libraries

My research produced the list of packages below. The chunk below checks your environment for the needed packages and installs them. If this file is opened as a r Markdown file, r will not evaluate the chunk below.


```{r eval=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)

pkg <- c("devtools", "shiny", "ggplot2", "knitr","data.table",
         "profvis", "rmarkdown", "shinythemes" "shiny","DT","tcltk2")
new.pkg <- pkg[!(pkg %in% installed.packages())]
new.pkg

# If there are any packages in the list that aren't installed,
# install them
if (length(new.pkg)) {
  install.packages(new.pkg, repos = "http://cran.rstudio.com")
}
installed.packages()
```

#Load The Data into the Global Environment
Next, I loaded the data into my environment.
**Note** - I manually changed the names of some of the columns so that all of the columns followed the same naming convention. So, the original tables won't work.

```{r results='hide'}
#Clear the Enviornment
rm(list=ls())

#Personal Laptop Directory
offLoc <- read.csv("C:\\Users\\Green_Winter\\Desktop\\Data Files\\Office Location Table.csv")
machLUT <- read.csv("C:\\Users\\Green_Winter\\Desktop\\Data Files\\\\Machine Lookup Table.csv")
mach <- read.csv("C:\\Users\\Green_Winter\\Desktop\\Data Files\\Machine Table.csv")
sensorLUT <- read.csv("C:\\Users\\Green_Winter\\Desktop\\Data Files\\Sensor Lookup Table.csv")
sensorRead <- read.csv("C:\\Users\\Green_Winter\\Desktop\\Data Files\\Sensor Readings.csv")
Sensor <- read.csv("C:\\Users\\Green_Winter\\Desktop\\Data Files\\Sensor Table.csv")
```

#Conduct Data Discovery
Next, I conducted discovery on the tables to make sure all variables are aligned with their description. I skipped running code on the Office Location table  since it only has 5 observations. Although the Machine and Machine Look-up tables are also small, I wanted to be sure that I didn't miss any duplicates, outliers, or missing values.

```{r}
summary(mach)
summary(machLUT)
summary(offLoc)
summary(sensorLUT)
#Check for duplicate records in the Sensor Lookup Table
length(duplicated(sensorLUT))
summary(sensorRead)
#Check for duplicate records in the Sensor Readings Table
length(duplicated(sensorRead))
```

In the Sensor Readings table there are `r sum(sensorRead$Sensor_Value>.9)` readings above the spiked range. This may be of critical concern to the client.


#Create and Execute Data Model - Transform the Data for Reporting
After discovering the data, I created a data model visual to determine the relationships between the tables. I also used the data model to determine which dummy variables I'd create, which variables work as foreign and primary keys, and how to validate that the running log table had aggregated all of the source tables' entries properly (i.e.  counts of unique variables under fields). 

![AF OEA Sensor System Relational Database Model](C:\Users\Green_Winter\Desktop\Data Files\Data Model.png)
**2DB Completed**


#Join The Data and Create the Base Log
The following chunk are the procedures needed to join the source tables together and create an empty master table to be populated.

```{r }
#Create unique IDs for the algorithm that will later randomly pick a sensor and a machine
sensorRead$Sensor_Algo_ID <- rownames(sensorRead)
machLUT$Mach_Algo_ID <- rownames(machLUT)
#Create a dataframe that R can use as a lookup table/foreign key to append the generated sensor 
#readings to the sensor IDs in a later algorithm
sensorRead_Algo <-sensorRead
#Merge the Machine Lookup, Office Location, and Machine Tables and create a Master Machine Table
offMach <- merge(machLUT, offLoc, by.x ="Location_ID", all= TRUE)
logMach <- merge(offMach,mach, by.x = "Machine_ID", all= TRUE)
rm(offMach)
#Merge the Sensor Look Up, Sensor, and Sensor Reading Tables with the Master Machine Table
log.01 <- merge(logMach, sensorLUT, by.y = "Machine_ID", all = TRUE)
rm(logMach)
log.02 <-merge(log.01, sensorRead_Algo, by.x = "Sensor_ID",all=TRUE)
#Keep Master.01 for merging newly generated sensor data to the rest of the Master Table's fields
log <- merge(log.02, Sensor, by.y = "Sensor_ID", all=TRUE)
#Create a column for Iteration/System Time stamps
log$Sys_Time <- Sys.time()
#Create a flag for the sensor readings where TRUE when the reading is abnormal
log$Reading_Flag <- FALSE
log$Reading_Flag[log$Sensor_Value>.5] <- TRUE
log$PK <- rownames(log)
#Create an empty master table
master <- data.frame()
```

#Build Color Paletts for Visualizations
The following chunk calls the libraries, create subsetted data sources, and stores the color palettes needed for the visualizations. Each # code is a hex color.

```{r}
library(ggplot2)
library(data.table)
library(DT)

#Formatting the charts, tables, and plots
# The palette with grey:
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442",
               "#0072B2", "#D55E00", "#CC79A7")
# The palette with black:
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
tol21rainbow <- c("#771155", "#AA4488", "#CC99BB", "#114477", "#4477AA",
                  "#77AADD", "#117777", "#44AAAA", "#77CCCC", "#117744", 
                  "#44AA77", "#88CCAA", "#777711", "#AAAA44", "#DDDD77", 
                  "#774411", "#AA7744", "#DDAA77", "#771122", "#AA4455", "#DD7788")

locationSpecific <- data.table(master[master$Location=="New York",])
```

###Build Visualizations for the Executive Dashboard

The following chunk are the tables, graphs, and charts displayed on the executive dashboard I built. 
*Note* These code chunks are tied to the stagnant version of the the master table. The content of the executive dashboard is not tied to this chunk.

```{r eval=FALSE}
#Create a dynamic table that is location specific
#The By argument will be changeable to these inputs: Machine Type, Sensor Type, Reading Flag
execChangeTable <- locationSpecific[,{Count_Readings=length(Sensor_Value)
    Count_Abnormal_Readings=sum(Reading_Flag)    
    Average_Reading=round(mean(Sensor_Value), digits=2)
    Min_Reading = min(Sensor_Value)
    Max_Reading = max(Sensor_Value)
    Perc_Abnormal_Readings= (round(mean(Reading_Flag), digits = 3))*100
    Perc_Normal_Readings=(round(1-(mean(Reading_Flag)), digits = 3))*100
    list(Count_Readings=Count_Readings,Count_Abnormal_Readings=Count_Abnormal_Readings,
         Average_Reading=Average_Reading, Min_Reading=Min_Reading,Max_Reading=Max_Reading,
         Perc_Abnormal_Readings=Perc_Abnormal_Readings, 
         Perc_Normal_Readings=Perc_Normal_Readings)},by=Sensor_Type]

print(execChangeTable)

```

```{r results='asis'}
#Create a bar chart that compares the overall number of normal and abnormal 
#readings per location
ggplot(master, aes(Reading_Flag))+geom_bar(aes(fill = Reading_Flag))+facet_grid(.~ Location)+theme(axis.text.x=element_blank())+scale_fill_manual(values=cbbPalette[2:3],
                   name="Sensor Reading Flag",
                   breaks=c(TRUE,FALSE),
                   labels=c("Abnormal","Normal"))+labs(title = "Count of Abnormal vs. Normal Sensor Readings")

#A Dot Plot that shows the distribution of sensor values by location
ggplot(master, aes(y=Sensor_Value, x=Location, fill=Location))+
  geom_dotplot(stackratio = .7, binwidth = .01,binaxis = "y", 
               stackdir = "center")+
  scale_fill_manual(values = c("#FFFFFF","#E95420","#026d62",
                               "#2C001E","#b3680a"))+labs(title = "Distribution of Sensor Readings for Each Site")

#Create a histogram that shows the distribution of sensor readings for one 
#location (bins =.1) with each bin chunked and color coded by sensor ID
ggplot(locationSpecific, aes(Sensor_Value,fill=Sensor_ID))+
   geom_histogram(binwidth = .1)+scale_fill_manual(values=tol21rainbow)+labs(title = "Variability of Sensor Readings for Each Machine at New York Site", subtitle="Color Coded by Sensor ID")

#A Box Plot that shows the distribution of sensor values by Machine Id for one location
ggplot(locationSpecific, aes(y=Sensor_Value, x=Machine_ID, fill=Machine_ID))+
  geom_boxplot()+scale_colour_manual(values=cbPalette)+labs(title = "Variability of Sensor Readings for Each Machine at New York Site")
```


#Build Visualizations for the Operations Dashboard
The following chunk are the tables, graphs, and charts displayed on the operations dashboard. 
*Note* These code chunks are tied to the stagnant version of the the master table. The content of the operations dashboard is not tied to this chunk.

```{r eval=FALSE}
#Create a high level performance table that is location specific
#Later change the by argument to inputs: Machine Type, Machine ID, Sensor Type, Sensor ID
mapTable <- locationSpecific[,{Count_Readings=length(Sensor_Value)
    Count_Abnormal_Readings=sum(Reading_Flag)
    Average_Reading=round(mean(Sensor_Value), digits=2)
    Min_Reading = min(Sensor_Value)
    Max_Reading = max(Sensor_Value)
    Perc_Abnormal_Readings= (round(mean(Reading_Flag), digits = 3))*100
    Perc_Normal_Readings=(round(1-(mean(Reading_Flag)), digits = 3))*100
    list(Count_Readings=Count_Readings, Count_Abnormal_Readings=Count_Abnormal_Readings, 
         Average_Reading=Average_Reading, Min_Reading=Min_Reading, Max_Reading=Max_Reading,
         Perc_Abnormal_Readings=Perc_Abnormal_Readings,
         Perc_Normal_Readings=Perc_Normal_Readings)},
   by=.(Machine_Type, Sensor_Type)]

print(mapTable)
```

```{r}
#Create a histogram that shows the distribution of sensor readings for one 
#location (bins =.1) with each bin chunked and color coded by sensor ID.
ggplot(locationSpecific, aes(Sensor_Value,fill=Sensor_ID))+geom_histogram(binwidth = .1)+
  scale_fill_manual(values=tol21rainbow)+facet_grid(. ~Machine_ID)+labs(title = "Distribution of Sensor Readings for New York Site")

#Create a line chart that shows sensor readings vs system time for one 
#particular location's and one particular machine's sensors.
ggplot(locMachSpecific, aes(x=Sys_Time, y=Sensor_Value, group=Sensor_ID, colour=Sensor_ID))+
  geom_line(size=1)+scale_colour_manual(values=cbPalette)+labs(title = "Sensor Readings for New York Site Over Time")

```
